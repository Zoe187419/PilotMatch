---
title: "Simulations with SITA Violation"
author: "Rachael Caelie (Rocky) Aikens"
date: "2/13/2020"
output: pdf_document
---

```{r setup, warning=FALSE, message = FALSE, include = FALSE}
knitr::opts_chunk$set(cache=FALSE, warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center", fig.height = 4)
require(ggplot2)
require(dplyr)
require(gridExtra)
require(ggpubr)
theme_set(theme_light())
source("../code/basic_sim_functions.R")
source("../code/SITA_violation_sim_functions.R")
```

# Set Up with SITA violations

We compare the performance of propensity score matching, Mahalanobis distance matching, and Buffalo Matching (described in the previous section) on simulated data, varying the dimensionality of the problem, the fixed treatment to control ratio during matching, and the correlation between the true propensity and prognostic score. For this set of simulations, we also add a weak, unobserved confounder, U. 
\begin{align*}
    X_i &\sim_{iid} \text{Normal}(0,I_p),\\
    T_i &\sim_{iid} \text{Bernoulli}\left(\frac{1}{1+\exp(-\phi(X_i))}\right),\\
    Y_i &=\tau T_i + \Psi(X_i) + \epsilon_i,\\
    \epsilon_i &\sim_{iid} N(0,\sigma^2),
\end{align*}
where the true propensity and prognositic scores are given by the linear combinations
\begin{align*}
    \phi(X_i) &= X_{i1}/3 - \nu U c,\\
    \Psi(X_i) &=\rho X_{i1} + \sqrt{(1-\rho^2)}X_{i2} + \nu U,
\end{align*}
The constant, $c$ in the propensity score formula was chosen such that there were approximately 100 treated observations in each dataset. For the simulations reported in the main figures of the paper, we let $c = 3$. We consider $p=10$, $\rho = 0, 0.1,\hdots, 0.9, 1.0,$ and $k=1,\hdots, 10$. Each simulation consisted of a dataset of size $n=2000$ and was repeated $N=1000$ times.
We fix the treatment effect to be constant with $\tau=1$ and the noise to be $\sigma=1$.
For a given matching, we estimate ATT and design sensitivity $\tilde\Gamma$ using the permutation $t$-statistic from the package `sensitivtymv`

\pagebreak

# Fisher-Mill Visualizations

This set-up is a little weird.  Here are some Fisher-Mill plots of the resulting data:

```{r}
nu = 0.2

FM_plot_xSITA <- function(data, rho, nu = 0.2, title = ""){
  plt_data <- data %>%
    mutate(prog = rho*X1 + sqrt(1-rho^2)*X2 + nu * U,
           prop = mu,
           t = as.factor(abs(1-t)),
           a = ifelse(t == 1, 0.9, 1)) %>%
    dplyr::select(c(t, prog, prop, a))
  
  plt <- ggplot(data = plt_data, aes( x = prop, y = prog, group = t, color = t)) + 
    geom_point(size = 1, aes(alpha = a)) +
    scale_color_brewer(palette="Set1") +
    theme(legend.position = "none", aspect.ratio=1, plot.title = element_text(hjust = 0.5, size = 12))+
    ggtitle(title) +
    ylab(expression(paste("Prognostic Score, ", Psi, "(x)", sep = ""))) +
    xlab("Propensity Score, logit(e(x))")
  
  return(plt)
}
```

```{r, fig.height=4, fig.width=8}
a <- FM_plot_xSITA(generate_xSITA_data(true_mu = "X1/3-3", nu = nu), rho = 0, title = "rho = 0")
b <- FM_plot_xSITA(generate_xSITA_data(true_mu = "X1/3-3", nu = nu), rho = 0.5, title = "rho = 0.5")
c <- FM_plot_xSITA(generate_xSITA_data(true_mu = "X1/3-3", nu = nu), rho = 0.9, title = "rho = 0.9")
ggarrange(a,b,c, ncol = 3)
```

But there's something sinister going on here.  Suppose we fit the best possible model for propenisity and prognostic score.  That is, our coefficients for X1 and X2 in our propensity and prognostic models are exactly correct, but we leave out $U$ in the model because we never observed it. The plots below show the matches we might choose in this scenario under Mahalanobis, Propensity, and Joint Propensity and Prognostic score matching.  As you can see, we are missing some amount of variation between matched individuals.

```{r}
match_viz_xSITA <- function(data, match, rho, nu, k = 1, title = "Matching"){
  plt_data <- data %>% 
    mutate(m = match) %>%
    mutate(a = ifelse (is.na(m), 0.9, 1)) %>% 
    mutate(prog = rho*X1 + sqrt(1-rho^2)*X2 + nu * U, 
           prop = mu,
           t = as.factor(abs(1-t))) %>%
    dplyr::select(c(t, prog, prop, m, a))
  
  m_data <- plt_data %>% 
    filter(!is.na(m)) %>%
    arrange(m, desc(t)) %>% 
    mutate(id = rep(1:(k + 1), sum(data$t))) %>%
    dplyr::select(-c(t, a)) %>%
    group_by(m) %>%
    summarize(prop1 = first(prop), prop2 = last(prop),
              prog1 = first(prog), prog2 = last(prog)) %>%
    dplyr::select(prog1, prog2, prop1, prop2)
  
  plt <- ggplot(data = plt_data, aes( x = prop, y = prog, group = t, color = t)) + 
    geom_point(aes(alpha = a), size = 1)+
    scale_color_brewer(palette="Set1") +
    geom_segment(data = m_data, 
                 aes(x = prop1, y = prog1,
                     xend = prop2, yend = prog2),
                 color =  "black", group = NA, linetype = "dashed") +
    ggtitle( title)+
    theme(legend.position = "none", aspect.ratio=1, plot.title = element_text(hjust = 0.5, size = 9))+
    ylab(expression(paste(Psi, "(x)", sep = ""))) +
    xlab(expression(paste(phi, "(x)", sep = "")))
  
  return(plt)
}

# like prognostic match except returns data frame and match assignments, not just the
# reformatted dataframe of outcomes by match assignment
prognostic_match_assignment_xSITA <- function(df, propensity, match_assignment, prog_model, n_control) {
  df$m <- match_assignment
  df$row <- 1:nrow(df)
  n_t<- sum(df$t)

  selected <- df %>% 
    filter(!is.na(m)) %>%
    filter(t==0) %>%
    group_by(m) %>%
    sample_n(size = 1)
  
  prognostic <- lm(y ~ . - mu - t - row - m - U, data = selected)
  not_selected <- df[-selected$row, ]
  not_selected <- not_selected %>% 
			mutate(progscore = predict(prognostic, not_selected)) %>%
			mutate(propscore = predict(propensity, not_selected))
  prog_dist <- match_on(t ~ progscore + propscore, data = not_selected)
  prog_match <- pairmatch(prog_dist, controls = n_control, data = not_selected) 
  return(list(df = not_selected, match = prog_match, k = n_control))
}
```


```{r}
rho <- 0.5
#simulate data
df <- generate_xSITA_data(N = 2000, p = 10, true_mu = "X1/3-3", nu = nu, rho = rho, sigma = 1)
k = 1
prop_model = formula(t ~ . - mu - y - U)
prog_model = formula(y ~ . - mu - t - U)

# mahalanobis match
mahal_dist <- match_on(prop_model, method = "mahalanobis", data = df)
m_match <- pairmatch(mahal_dist, controls = k, df)
```

```{r}
#Calculate best possible propensity and prognostic scores, and match on those
oracle_df <- df %>% 
    mutate(prog = rho*X1 + sqrt(1-rho^2)*X2, 
           prop = 1/(1+exp(-(mu - nu * U))))

oracle_prop_match <- pairmatch(t ~ prop, controls = k, oracle_df)
oracle_prog_match <- pairmatch(t ~ prog + prop, controls = k, oracle_df)
```

If we made Fisher Mill plots from our scores and matched on them, this what we'd see:

```{r,  fig.width=8, fig.height= 3}
naive_df <- df %>%
  mutate(mu = mu - nu * U)

a <- match_viz_xSITA(naive_df, m_match, rho, nu = 0, title = "Mahalanobis Match")
b <- match_viz_xSITA(naive_df, oracle_prop_match, rho, nu = 0, title = "Best Propensity Match")
c <- match_viz_xSITA(naive_df, oracle_prog_match, rho, nu = 0, title = "Best Propensity x Prognosis Match")

ggarrange(a,b,c, ncol= 3, labels = "AUTO" )
```


But of course, the Fisher-Mill plots we make and the matches we select are missing the unobserved confounder, U.  If we made true Fisher-Mill plots based on the data generating functions, we'd see that the above matching scheme is not doing as well as we thought.


```{r, fig.width=8, fig.height= 3}
a <- match_viz_xSITA(df, m_match, rho, nu, title = "Mahalanobis Match")
b <- match_viz_xSITA(df, oracle_prop_match, rho, nu, title = "Best Propensity Match")
c <- match_viz_xSITA(df, oracle_prog_match, rho, nu, title = "Best Propensity x Prognosis Match")

ggarrange(a,b,c, ncol= 3, labels = "AUTO" )
```

\pagebreak

# Results with no SITA violation

```{r}
read_data_1000 <- function(i, path_to_file){
  filename <- paste(path_to_file, "angle_sigma1_results_",i,"_10_1000", sep = "")
  dat <- read.csv(filename) %>%
    mutate(rho = i/10)
  return(dat)
}

dat <- lapply(1:10, function(x) read_data_1000(x, "../data/tuning/mu_x1_over_3_minus_3/nsim_1000/")) %>% bind_rows %>% filter(k <= 5)
```

```{r}
true_tau <- 1

dat <- mutate(dat, 
              squared_err = (estimate-true_tau)**2,
              k = as.factor(k))

plt_data <- dat %>% 
  group_by(method, k, rho) %>% 
  summarize(Bias = mean(estimate) - true_tau, 
            median_gamma = median(gamma), 
            Standard.Deviation = sd(estimate),
            MSE = Bias^2 + Standard.Deviation^2) %>%
  ungroup() %>%
  mutate(method = recode(method, propensity = "Propensity", 
                         mahalanobis = "Mahalanobis", 
                         prognostic = "Pilot"))
```


```{r}
plt_data <- plt_data %>%
  mutate(method = factor(method, levels = c("Mahalanobis", "Propensity", "Pilot")))
```

```{r, fig.width=8.5, fig.height=6}
a <- ggplot(plt_data, aes(x = rho, y = Bias, group = k, color = k)) +
  geom_line() + geom_point() +
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) +
  scale_color_brewer(palette="RdYlBu")

b <- ggplot(plt_data, aes(x = rho, y = Standard.Deviation, group = k, color = k)) +
  geom_line() + geom_point() + facet_wrap(~method) +
  xlab(expression(paste("Correlation, ", rho)))+
  ylab("Standard Deviation")+
    ylim(0, NA) + 
  scale_color_brewer(palette="RdYlBu")

c <- ggplot(plt_data, aes(x = rho, y = MSE, group = k, color = k)) +
  geom_line() + geom_point() + 
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method)+
    ylim(0, NA) + 
  scale_color_brewer(palette="RdYlBu")

d <- ggplot(plt_data, aes(x = rho, y = median_gamma, group = k, color = k)) +
  geom_line() + geom_point() +
  ylab(expression(paste("Median ", Gamma))) +
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) + 
    ylim(0, NA) + 
  scale_color_brewer(palette="RdYlBu")

ggarrange(a, b, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")

```

Figure 1 shows the bias and variance of $1:k$ matching for each method on the same simulated data set as $k$ increases (colored lines) and the correllation of propensity and prognosis, $\rho$ increases from left to right.  When $\rho = 0$, the treatment effect is completely unconfounded, since treatment is entirely determined (up to randomness) by variation in $X_{i1}$, and outcome (under the control assignment) is entirely determined by variation in $X_{i2}$.  When $\rho = 1$, the data is highly confounded, since outcome and treatment assignment are both determined solely by variation in $X_{i1}$. 

A first observation is that the bias from Mahalanobis distance matching is large, and it increases with the correllation between prognosis and treatment assignment (Figure 1A). This is probably because, as $\rho$ approaches 1, only a single covariate, $X_{i1}$ is important to match on, yet Mahalanobis distance considers 9 other covariates which are entirely random noise unimportant to the problem. It thus selects worse matches with respect to the true covariate of interest. This problem is exacerbated when the number of uninformative covariates is increased (Supplementary Figure 3).

Figure 1B shows the protective effect of pilot matching against the variance of the estimator.  Propensity score matching has highest variance, and this is worse when $\rho$ is close to zero.  This is because, when $\rho$ is small, the propensity score contains no information about prognosis under the control assignment.  This causes the propensity score method to match observations which may be very different in terms of their potential outcome under the control assignment, giving poor prognostic balance and thus larger variance in the estimate of the causal effect.  While Mahalanobis distance performs slightly better, it is again choosing lower quality matches because of the uninformative covariates in the data. The lowest variance is achieved by pilot matching, since this algorithm optimizes for prognostic balance as well as propensity score balance.

```{r fig.width=8.5, fig.height=6, echo = FALSE}
ggarrange(c, d, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")
```

Figure 2 shows the mean squared error and median gamma sensitivity from the same set of simulations as above.  Figure 2A demonstrates that pilot matching does well compared to the other two methods in terms of mean squared error, because of the protection against bias and variance shown in figure 1. Figure 2B shows the protective effect of prognostic balance against unobserved confounding.  Propensity score matching gives lowest $\Gamma$ values, especially when $\rho$ is small. When this happens, the propensity score contains no prognostically relevant covariates, so the matches produced have poor prognostic balance.  As $\rho$ increases, the prognostic score and the propensity score become highly correllated, so matching on propensity score starts to give some prognostic balance as well as propensity balance.  While the Gamma sentistivity of Mahalanobis distance matching seems promising when $\rho$ is large, most of this is likely due to the large amount of bias in the effect estimate from this method (Figure 1A).  Because pilot matching directly attempts to achieve prognostic balance in the matched sets, the pilot matching method has better protection against unobserved confounding, without giving a highly biased estimator.

\pagebreak

# nu = 0.2

```{r}
read_xSITA_data_1000 <- function(i, path_to_file, nu){
  filename <- paste(path_to_file, "xSITA_results_",i,"_10_1000_nu_", nu * 10, sep = "")
  dat <- read.csv(filename) %>%
    mutate(rho = i/10)
  return(dat)
}

dat <- lapply(1:10, function(x) read_xSITA_data_1000(x, "../data/SITA_violations/nu_2/", 0.2)) %>% bind_rows
```


```{r}
true_tau <- 1

dat <-  dat %>%
  filter(k <= 5) %>%
  mutate(squared_err = (estimate-true_tau)**2,
        k = as.factor(k))

plt_data <- dat %>% 
  group_by(method, k, rho) %>% 
  summarize(Bias = mean(estimate) - true_tau, 
            median_gamma = median(gamma), 
            Standard.Deviation = sd(estimate),
            MSE = Bias^2 + Standard.Deviation^2) %>%
  ungroup() %>%
  mutate(method = recode(method, propensity = "Propensity", 
                         mahalanobis = "Mahalanobis", 
                         prognostic = "Pilot"))
```


```{r}
plt_data <- plt_data %>%
  mutate(method = factor(method, levels = c("Mahalanobis", "Propensity", "Pilot")))
```

```{r, fig.width=8.5, fig.height=10.5}
a <- ggplot(plt_data, aes(x = rho, y = Bias, group = k, color = k)) +
  geom_line() + geom_point() +
    ylim(0, NA) + 
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) +
  scale_color_brewer(palette="RdYlBu")

b <- ggplot(plt_data, aes(x = rho, y = Standard.Deviation, group = k, color = k)) +
  geom_line() + geom_point() + facet_wrap(~method) +
  xlab(expression(paste("Correlation, ", rho)))+
    ylim(0, NA) + 
  ylab("Standard Deviation")+
  scale_color_brewer(palette="RdYlBu")

c <- ggplot(plt_data, aes(x = rho, y = MSE, group = k, color = k)) +
  geom_line() + geom_point() + 
  xlab(expression(paste("Correlation, ", rho)))+
    ylim(0, NA) + 
  facet_wrap(~method)+
  scale_color_brewer(palette="RdYlBu")

d <- ggplot(plt_data, aes(x = rho, y = median_gamma, group = k, color = k)) +
  geom_line() + geom_point() +
  ylab(expression(paste("Median ", Gamma))) +
  xlab(expression(paste("Correlation, ", rho)))+
    ylim(0, NA) + 
  facet_wrap(~method) + 
  scale_color_brewer(palette="RdYlBu")

ggarrange(a, b, c, d, ncol = 1, nrow = 4, common.legend = TRUE, legend = "right", labels = "AUTO")

```









\pagebreak

# nu = 0.5

```{r}
dat <- lapply(1:10, function(x) read_xSITA_data_1000(x, "../data/SITA_violations/nu_5/", 0.5)) %>% bind_rows
```


```{r}
true_tau <- 1

dat <- dat %>%
  filter( k <= 5) %>%
  mutate(squared_err = (estimate-true_tau)**2,
         k = as.factor(k))

plt_data <- dat %>% 
  group_by(method, k, rho) %>% 
  summarize(Bias = mean(estimate) - true_tau, 
            median_gamma = median(gamma), 
            Standard.Deviation = sd(estimate),
            MSE = Bias^2 + Standard.Deviation^2) %>%
  ungroup() %>%
  mutate(method = recode(method, propensity = "Propensity", 
                         mahalanobis = "Mahalanobis", 
                         prognostic = "Pilot"))
```


```{r}
plt_data <- plt_data %>%
  mutate(method = factor(method, levels = c("Mahalanobis", "Propensity", "Pilot")))
```

```{r, fig.width=8.5, fig.height=10.5}
a <- ggplot(plt_data, aes(x = rho, y = Bias, group = k, color = k)) +
  geom_line() + geom_point() +
  ylim(0, NA) + 
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) +
  scale_color_brewer(palette="RdYlBu")

b <- ggplot(plt_data, aes(x = rho, y = Standard.Deviation, group = k, color = k)) +
  geom_line() + geom_point() + facet_wrap(~method) +
  xlab(expression(paste("Correlation, ", rho)))+
  ylim(0, NA) + 
  ylab("Standard Deviation")+
  scale_color_brewer(palette="RdYlBu")

c <- ggplot(plt_data, aes(x = rho, y = MSE, group = k, color = k)) +
  geom_line() + geom_point() + 
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method)+
  ylim(0, NA) + 
  scale_color_brewer(palette="RdYlBu")

d <- ggplot(plt_data, aes(x = rho, y = median_gamma, group = k, color = k)) +
  geom_line() + geom_point() +
  ylab(expression(paste("Median ", Gamma))) +
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) + 
  ylim(0, NA) + 
  scale_color_brewer(palette="RdYlBu")


ggarrange(a, b, c, d, ncol = 1, nrow = 4, common.legend = TRUE, legend = "right", labels = "AUTO")

```