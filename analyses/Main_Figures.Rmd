---
title: "Main Figures"
author: "Rachael Caelie (Rocky) Aikens"
date: "5/3/2019"
output: pdf_document
---


```{r setup, warning=FALSE, message = FALSE, include = FALSE}
knitr::opts_chunk$set(cache=TRUE, warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center", fig.height = 4)
require(ggplot2)
require(dplyr)
require(gridExtra)
require(ggpubr)
theme_set(theme_light())
source("../code/simulation_functions.R")
```

# Set Up 

We compare the performance of propensity score matching, Mahalanobis distance matching, and Buffalo Matching (described in the previous section) on simulated data, varying the dimensionality of the problem, the fixed treatment to control ratio during matching, and the correlation between the true propensity and prognostic score. The generative model for all of our simulations is the following:
\begin{align*}
    X_i &\sim_{iid} \text{Normal}(0,I_p),\\
    T_i &\sim_{iid} \text{Bernoulli}\left(\frac{1}{1+\exp(-\phi(X_i))}\right),\\
    Y_i &=\tau T_i + \Psi(X_i) + \epsilon_i,\\
    \epsilon_i &\sim_{iid} N(0,\sigma^2),
\end{align*}
where the true propensity and prognositic scores are given by the linear combinations
\begin{align*}
    \phi(X_i) &= X_{i1}/3-3,\\
    \Psi(X_i) &=\rho X_{i1} + \sqrt{(1-\rho^2)}X_{i2},
\end{align*}
so that $\text{Cor}(\phi(X_i), \Psi(X_i)) \propto \rho$.  The propensity score formula was chosen such that there were approximately 100 treated observations in each dataset. We consider $p=10$, $\rho = 0, 0.1,\hdots, 0.9, 1.0,$ and $k=1,\hdots, 10$. Each simulation consisted of a dataset of size $n=2000$ and was repeated $N=1000$ times.
We fix the treatment effect to be constant with $\tau=1/2$ and the noise to be $\sigma=1$.
For a given matching, we estimate ATT and design sensitivity $\tilde\Gamma$ using the permutation $t$-statistic from the package `sensitivtymv`

\pagebreak

# Motivation

The figure below gives a heuristic representation of what this algorithm is attempting to do.  We imagine a scenario in which each individual in our data set, both treated and control, is represented in a reduced space of only two covariates: The variation determining the treatment assignment ($\phi(X_i)$), and the variation determining the outcome ($\Psi(X_i)$). These are the two features which are directly relevant to our matching: $\phi(X_i)$ balance (propensity balance) reduces bias, and $\Psi(X_i)$ balance (prognostic balance) reduces bias as well as variance and sensitivity to unobserved confounding. 

In our simulation, $\phi(X_i)$ and $\Psi(X_i)$ are known linear combinations of the covariates (see set up), so we can visualize them directly.  For simplicity, we assume that the prognosis and treatment assignment are entirely uncorrellated ($\rho = 0$), although this need not always be the case (See supplementary figures 1 and 2). Optimal mahalanobis distance matching (Figure 1A), pairs individuals who are closest in the full covariate space.  However, since only $X_{i1}$ and $X_{i2}$ are important for prognosis and treatment assignment, individuals who are close in the full covariate space may be very distant in the feature space of $\phi(X_i)$ and $\Psi(X_i)$. Propensity score matching (Figure 1B) pairs individuals who are close in the axis important for treatment assigment, $\phi(X_i)$, but not for prognosis, $\Psi(X_i)$.  This matching will reduce bias compared to the unmatched dataset, but will lose the protection from variance and unobserved confounding conferred by prognostic balance.  In contrast, if we match jointly on $\phi(X_i)$ and $\Psi(X_i)$, we obtain individuals who are close together in the feature space below.  This optimizes for both desirable types of covariate balance: prognostic and propensity.

```{r}
match_viz <- function(data, match, rho, k = 1, title = "Matching"){
  plt_data <- data %>% 
    mutate(m = match) %>%
    mutate(a = ifelse (is.na(m), 0.9, 1)) %>% 
    mutate(prog = rho*X1 + sqrt(1-rho^2)*X2, 
           prop = mu,
           t = as.factor(abs(1-t))) %>%
    select(c(t, prog, prop, m, a))
  
  m_data <- plt_data %>% 
    filter(!is.na(m)) %>%
    arrange(m, desc(t)) %>% 
    mutate(id = rep(1:(k + 1), sum(data$t))) %>%
    select(-c(t, a)) %>%
    group_by(m) %>%
    summarize(prop1 = first(prop), prop2 = last(prop),
              prog1 = first(prog), prog2 = last(prog)) %>%
    select(prog1, prog2, prop1, prop2)
  
  plt <- ggplot(data = plt_data, aes( x = prop, y = prog, group = t, color = t)) + 
    geom_point(aes(alpha = a))+
    scale_color_brewer(palette="Set1") +
    geom_segment(data = m_data, 
                 aes(x = prop1, y = prog1,
                     xend = prop2, yend = prog2),
                 color =  "black", group = NA, linetype = "dashed") +
    ggtitle( title)+
    theme(legend.position = "none", aspect.ratio=1, plot.title = element_text(hjust = 0.5, size = 8))+
    ylab(expression(paste(Psi, "(x)", sep = ""))) +
    xlab(expression(paste(phi, "(x)", sep = "")))
  
  return(plt)
}

overlap_histogram <- function(data){
    plt_data <- data %>% 
      mutate(prog = rho*X1 + sqrt(1-rho^2)*X2, 
           prop = mu,
           t = as.factor(abs(1-t))) %>%
      select(c(t, prog, prop))
    
    ggplot(plt_data, aes(x = prop, fill = t)) + geom_histogram(alpha = 0.4, position = "identity")
}

# like prognostic match except returns data frame and match assignments, not just the
# reformatted dataframe of outcomes by match assignment
prognostic_match_assignment <- function(df, propensity, match_assignment, prog_model, n_control) {
  df$m <- match_assignment
  df$row <- 1:nrow(df)
  n_t<- sum(df$t)

  selected <- df %>% 
    filter(!is.na(m)) %>%
    filter(t==0) %>%
    group_by(m) %>%
    sample_n(size = 1)
  
  prognostic <- lm(y ~ . - mu - t - row - m, data = selected)
  not_selected <- df[-selected$row, ]
  not_selected <- not_selected %>% 
			mutate(progscore = predict(prognostic, not_selected)) %>%
			mutate(propscore = predict(propensity, not_selected))
  prog_dist <- match_on(t ~ progscore + propscore, data = not_selected)
  prog_match <- pairmatch(prog_dist, controls = n_control, data = not_selected) 
  return(list(df = not_selected, match = prog_match, k = n_control))
}
```

```{r}
rho <- 0
#simulate data
df <- generate_data(N = 2000, p = 10, true_mu = "X1/3-3", rho = rho, sigma = 1)
k = 1
prop_model = formula(t ~ . - mu - y)
prog_model = formula(y ~ . - mu - t)

# mahalanobis match
mahal_dist <- match_on(prop_model, method = "mahalanobis", data = df)
m_match <- pairmatch(mahal_dist, controls = k, df)
```


```{r}
#Calculate true propensity and prognostic score, and match on the true score
oracle_df <- df %>% 
    mutate(prog = rho*X1 + sqrt(1-rho^2)*X2, 
           prop = 1/(1+exp(-(mu))))

oracle_prop_match <- pairmatch(t ~ prop, controls = k, oracle_df)
oracle_prog_match <- pairmatch(t ~ prog + prop, controls = k, oracle_df)
```

```{r, fig.width=8.5, fig.height= 3.5}
a <- match_viz(df, m_match, rho, title = "Mahalanobis Match")
b <- match_viz(df, oracle_prop_match, rho, title = "True Propensity Match")
c <- match_viz(df, oracle_prog_match, rho, title = "True Propensity x Prognosis Match")

ggarrange(a,b,c, ncol= 3, labels = "AUTO" )
```

```{r save to Figures folder}
pdf("../figures/Figure1.pdf",  width=8.5, height=3.5)
ggarrange(a,b,c, ncol= 3, labels = "AUTO" )
dev.off()
```

# Results 

Below, we use the simulation parameters described in the set up to estimate the bias, variance, mse, and median gamma sensitivity of effect estimates produced from Mahalanobis distance matching, propensity score matching, and Buffalo matching.

```{r}
read_data_1000 <- function(i, path_to_file){
  filename <- paste(path_to_file, "angle_sigma1_results_",i,"_10_1000", sep = "")
  dat <- read.csv(filename) %>%
    mutate(rho = i/10)
  return(dat)
}

dat <- lapply(1:10, function(x) read_data_1000(x, "../data/tuning/mu_x1_over_3_minus_3/nsim_1000/")) %>% bind_rows
```

```{r}
true_tau <- 1

dat <- mutate(dat, 
              squared_err = (estimate-true_tau)**2,
              k = as.factor(k))

plt_data <- dat %>% 
  group_by(method, k, rho) %>% 
  summarize(Bias = abs(mean(estimate) - true_tau), 
            median_gamma = median(gamma), 
            Standard.Deviation = sd(estimate),
            MSE = Bias^2 + Standard.Deviation^2) %>%
  ungroup() %>%
  mutate(method = recode(method, propensity = "Propensity", 
                         mahalanobis = "Mahalanobis", 
                         prognostic = "Buffalo"))
```


```{r, echo = FALSE}
plt_data <- plt_data %>%
  mutate(method = factor(method, levels = c("Mahalanobis", "Propensity", "Buffalo")))
```

```{r, fig.width=8.5, fig.height=6, echo = FALSE}
a <- ggplot(plt_data, aes(x = rho, y = Bias, group = k, color = k)) +
  geom_line() + geom_point() +
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) +
  scale_color_brewer(palette="RdYlBu")

b <- ggplot(plt_data, aes(x = rho, y = Standard.Deviation, group = k, color = k)) +
  geom_line() + geom_point() + facet_wrap(~method) +
  xlab(expression(paste("Correlation, ", rho)))+
  scale_color_brewer(palette="RdYlBu")

c <- ggplot(plt_data, aes(x = rho, y = MSE, group = k, color = k)) +
  geom_line() + geom_point() + 
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method)+
  scale_color_brewer(palette="RdYlBu")

d <- ggplot(plt_data, aes(x = rho, y = median_gamma, group = k, color = k)) +
  geom_line() + geom_point() +
  ylab(expression(paste("Median ", Gamma))) +
  xlab(expression(paste("Correlation, ", rho)))+
  facet_wrap(~method) + 
  scale_color_brewer(palette="RdYlBu")

ggarrange(a, b, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")

```

```{r fig.width=8.5, fig.height=6, echo = FALSE}
p <- ggarrange(a, b, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")

ggsave("../figures/Figure2.pdf", p,  width=8.5, height=5.5)
```

Figure 1 shows the bias and variance of $1:k$ matching for each method on the same simulated data set as $k$ increases (colored lines) and the correllation of propensity and prognosis, $\rho$ increases from left to right.  When $\rho = 0$, the treatment effect is completely unconfounded, since treatment is entirely determined (up to randomness) by variation in $X_{i1}$, and outcome (under the control assignment) is entirely determined by variation in $X_{i2}$.  When $\rho = 1$, the data is highly confounded, since outcome and treatment assignment are both determined solely by variation in $X_{i1}$. 

A first observation is that the bias from Mahalanobis distance matching is large, and it increases with the correllation between prognosis and treatment assignment (Figure 1A). This is probably because, as $\rho$ approaches 1, only a single covariate, $X_{i1}$ is important to match on, yet Mahalanobis distance considers 9 other covariates which are entirely random noise unimportant to the problem. It thus selects worse matches with respect to the true covariate of interest. This problem is exacerbated when the number of uninformative covariates is increased (Supplementary Figure 3).

Figure 1B shows the protective effect of Buffalo matching against the variance of the estimator.  Propensity score matching has highest variance, and this is worse when $\rho$ is close to zero.  This is because, when $\rho$ is small, the propensity score contains no information about prognosis under the control assignment.  This causes the propensity score method to match observations which may be very different in terms of their potential outcome under the control assignment, giving poor prognostic balance and thus larger variance in the estimate of the causal effect.  While Mahalanobis distance performs slightly better, it is again choosing lower quality matches because of the uninformative covariates in the data. The lowest variance is achieved by Buffalo matching, since this algorithm optimizes for prognostic balance as well as propensity score balance.

```{r fig.width=8.5, fig.height=6, echo = FALSE}
ggarrange(c, d, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")
```

```{r fig.width=8.5, fig.height=6, echo = FALSE}
p <- ggarrange(c, d, ncol = 1, nrow = 2, common.legend = TRUE, legend = "right", labels = "AUTO")

ggsave("../figures/Figure3.pdf", p,  width=8.5, height=5.5)
```

Figure 2 shows the mean squared error and median gamma sensitivity from the same set of simulations as above.  Figure 2A demonstrates that Buffalo does well compared to the other two methods in terms of mean squared error, because of the protection against bias and variance shown in figure 1. Figure 2B shows the protective effect of prognostic balance against unobserved confounding.  Propensity score matching gives lowest $\Gamma$ values, especially when $\rho$ is small. When this happens, the propensity score contains no prognostically relevant covariates, so the matches produced have poor prognostic balance.  As $\rho$ increases, the prognostic score and the propensity score become highly correllated, so matching on propensity score starts to give some prognostic balance as well as propensity balance.  While the Gamma sentistivity of Mahalanobis distance matching seems promising when $\rho$ is large, most of this is likely due to the large amount of bias in the effect estimate from this method (Figure 1A).  Because Buffalo matching directly attempts to achieve prognostic balance in the matched sets, the Buffalo method has better protection against unobserved confounding, without giving a highly biased estimator.


